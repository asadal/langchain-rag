import streamlit as st
from langchain.vectorstores.chroma import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
# from create_database import generate_data_store
import os

# these three lines swap the stdlib sqlite3 lib with the pysqlite3 package
__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

CHROMA_PATH = "chroma"

PROMPT_TEMPLATE = """
ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì€ ë‹¤ìŒ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•©ë‹ˆë‹¤:

{context}

---

ìœ„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ì§ˆë¬¸ì˜ ë‹µë³€: {question}
"""

def chat_with_db(query_text):
    embedding_function = OpenAIEmbeddings()
    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)
    results = db.similarity_search_with_relevance_scores(query_text, k=3)
    if len(results) == 0 or results[0][1] < 0.7:
        return "ê´€ë ¨ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    context_text = "\n\n---\n\n".join([doc.page_content for doc, _score in results])
    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)
    prompt = prompt_template.format(context=context_text, question=query_text)
    model = ChatOpenAI()
    response = model.invoke(prompt)  # `invoke` ë©”ì„œë“œ ì‚¬ìš©
    # ì‘ë‹µì—ì„œ 'content' í‚¤ì˜ ê°’ì„ ë°˜í™˜
    response_text = response.content
    return response_text

def main():# title nad fabicon
    st.set_page_config(page_title = "Hani Kyori Bot", page_icon = "https://img.hani.co.kr/imgdb/original/2024/0116/1817053905854034.png")

    # featured image
    st.image("https://flexible.img.hani.co.kr/flexible/normal/240/240/imgdb/original/2021/0524/20210524502287.jpg", width=100)

    st.title("ê²¨ë¦¬ë´‡")
    st.markdown("í•œê²¨ë ˆ í›„ì›íšŒì› 'ì„œí¬í„°ì¦ˆ ë²—'ì„ ìœ„í•œ ì¸ê³µì§€ëŠ¥ ì±—ë´‡ì…ë‹ˆë‹¤. í›„ì›íšŒì› ê´€ë ¨ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”.")

    # generate_data_store()

    if 'chat_history' not in st.session_state:
            st.session_state.chat_history = []

    for content in st.session_state.chat_history:
        with st.chat_message(content["role"]):
            st.markdown(content['message'])

    # `st.chat_input`ìœ¼ë¡œ ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°.
    if prompt := st.chat_input("í•œê²¨ë ˆ í›„ì›íšŒì›ì´ ë­”ê°€ìš”?"):
        with st.chat_message("user", avatar="ğŸ§‘"):
            st.markdown(prompt)
            st.session_state.chat_history.append({"role": "user", "message": prompt})
    # user_input = st.chat_input("Ask Kyori:", key="chat_input")

        # ì±—ë´‡ìœ¼ë¡œë¶€í„° ì‘ë‹µ ë°›ê¸°
        with st.chat_message("Kyori", avatar="https://raw.githubusercontent.com/asadal/langchain-rag/main/images/kyori.png"):
            response = chat_with_db(prompt)
            st.markdown(response)
            st.session_state.chat_history.append({"role": "Kyori", "message": response})
    # if user_input:
    #     response = chat_with_db(user_input)
    #     st.chat_message("User").write(user_input)
    #     st.chat_message("Kyori").write(response)  # ì‘ë‹µ ì¶œë ¥

if __name__ == "__main__":
    main()
